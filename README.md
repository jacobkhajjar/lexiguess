# Lexiguess

Running lexiguess.py will prompt the user to enter one or more words to analyze and return the lexical sets for each word.

Lexical sets were defined by the linguist John C. Wells as a way to categorize vowels across accents, particularly General American and British RP. This tool will search the Carnegie Melon University (CMU) pronunciation dictionary for North American English, and a British RP pronunciation dictionary generated by Montreal Forced Aligner 3.0 (MFA).

It is worth noting that this program is only a best estimate of the lexical sets based on comparing the CMU and MFA pronunciation dictionaries as well as spelling rules defined by Eric Armstrong in his book "Lexical Sets for Actors". Some sets, especially NORTH and FORCE, are especially difficult to differentiate and therefore this tool is best used with caution and should always be double-checked before trusting the result.

## Usage

Run lexiguess.py. It will request an input which should be a list of one or more words separated by whitespace. These words will be searched first in the CMU pronunciation dictionary and secondly, if necessary, in the MFA RP dictionary to return the estimated lexical sets of each word. Homonyms in the CMU dictionary will be detected and all homonyms of each word will be outputted. Optionally the program can also provide a transcription in the International Phonetic Alphabet (IPA), ARPAbet, or in configurable "fauxnetics" which are set by default to a General American bias.

### Arguments

-v --verbose provides word count and dictionary entries used in determining lexical sets

-fx --fauxnetics provides a General American biased "fauxnetic" transcription with phones configurable in /config/fx.py

### Config Options

The fx.py file found in the config folder can be edited to customize the output of the "fauxnetics" (fx). These phones are primarily defined by their ARPAbet symbols and by default are biased towards General American, although when configured will adapt to most accents that follow lexical set boundaries.

## Dictionaries

Lexiguess comes batteries included with two primary JSON dictionaries found in /dictionaries; us.json which is adapted from the CMU North American Pronunciation Dictionary (using the ARPAbet) and uk.json which is adapted from the MFA RP Pronunciation Dictionary (using the IPA). The dictionaries are configurable via their "pretty" counterparts found in /dictionaries/pretty.

### Dictionary Functions

#### dict_manipulate

This program will guide the user through a series of prompts to find or replace within the "pretty" dictionaries.

#### update_dict

This program will apply changes to the "pretty" us.dict and uk.dict files to the corresponding JSON file for use in the program. Changes to the "pretty" dictionaries will not reflect in any functions without running this program first.

## Credit

The CMU Dictionary is the primary reference for this tool.
http://www.speech.cs.cmu.edu/cgi-bin/cmudict

Secondarily the RP Pronunciation dictionary from MFA is checked in cases where British pronunciations are requested, or when North American English is not sufficient to determine the lexical set.
https://mfa-models.readthedocs.io/en/latest/dictionary/English/English%20%28UK%29%20MFA%20dictionary%20v3_1_0.html#English%20(UK)%20MFA%20dictionary%20v3_1_0

Finally when comparing against pronunciation dictionaries is not enough, the program will apply spelling rules as defined by Eric Armstrong in his extraordinary book "Lexical Sets for Actors".
https://ecampusontario.pressbooks.pub/lexicalsets/

All three sources are available through Creative Commons Licensing.

# Boot.Dev

This project is my first personal project for the Boot.Dev coding course

https://www.boot.dev/

This incredible site has taught me everything needed to build this tool, and I cannot recommend it strongly enough.

## Helper Functions

These functions were written to aid in the editing and creation of the various functions and documents throughout the tool and are included for completeness. These are not recommended or intended for further use.
